{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "random_state = 0\n",
    "with open('fewrel_val.json') as fp:\n",
    "    data_val = json.load(fp)\n",
    "with open('fewrel_train.json') as fp:\n",
    "    data_train = json.load(fp)\n",
    "l1 = [[data['tokens'], key] for key in data_train.keys() for data in data_train[key] ]\n",
    "l2 = [[data['tokens'], key] for key in data_val.keys() for data in data_val[key] ]\n",
    "df = pd.DataFrame(l1+l2, columns=['words', 'label'])\n",
    "df['sentence'] = df['words'].apply(lambda l: \" \".join(l))\n",
    "df = df[['sentence', 'label']]\n",
    "df.columns = ['text', 'label']\n",
    "len(data_train.keys()), len(data_val.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_dev_test = train_test_split(df, test_size=0.2, stratify=df.label, \n",
    "                                     shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_dev, df_test = train_test_split(df_dev_test, test_size=0.5, stratify=df_dev_test.label, \n",
    "                                     shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44800, 2), (5600, 2), (5600, 2))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape, df_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('ori_train.tsv', sep='\\t', index=False)\n",
    "df_dev.to_csv('ori_dev.tsv', sep='\\t', index=False)\n",
    "df_test.to_csv('ori_test.tsv', sep='\\t', index=False)\n",
    "df.to_csv('all.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9:(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\" : \", \":\", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "def clean_str_vn(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[~`@#$%^&*-+]\", \" \", string)    \n",
    "    def sharp(str):\n",
    "        b = re.sub('\\s[A-Za-z]\\s\\.', ' .', ' '+str)\n",
    "        while (b.find('. . ')>=0): b = re.sub(r'\\.\\s\\.\\s', '. ', b)\n",
    "        b = re.sub(r'\\s\\.\\s', ' # ', b)\n",
    "        return b\n",
    "    string = sharp(string)\n",
    "    string = re.sub(r\" : \", \":\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alekseyenko , alekseenko , alexeenko   is a russified form of the ukrainian surname oleksienko derived from the first name oleksiy ,  from greek alexius russian:aleksey \n"
     ]
    }
   ],
   "source": [
    "text = 'alekseyenko , alekseenko , alexeenko \\( \\) is a russified form of the ukrainian surname oleksienko derived from the first name oleksiy , \\( from greek alexius russian:aleksey \\)'\n",
    "text = text.replace(\"\\(\",\"\")\n",
    "text = text.replace(\"\\)\",\"\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P403' 'P1435' 'P206' 'P39' 'P127' 'P155' 'P140' 'P241' 'P412' 'P106'\n",
      " 'P264' 'P3450' 'P355' 'P400' 'P1408' 'P463' 'P1923' 'P460' 'P706' 'P57'\n",
      " 'P413' 'P740' 'P306' 'P40' 'P17' 'P4552' 'P176' 'P1303' 'P150' 'P59'\n",
      " 'P410' 'P159' 'P58' 'P175' 'P527' 'P123' 'P31' 'P495' 'P131' 'P407'\n",
      " 'P156' 'P178' 'P1344' 'P1001' 'P641' 'P27' 'P674' 'P466' 'P177' 'P25'\n",
      " 'P361' 'P3373' 'P364' 'P135' 'P710' 'P551' 'P276' 'P22' 'P750' 'P6'\n",
      " 'P118' 'P101' 'P102' 'P449' 'P1346' 'P136' 'P1411' 'P1877' 'P2094' 'P26'\n",
      " 'P105' 'P137']\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.load('labels.npy')\n",
    "print(a)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.935964285714284\n",
      "36\n",
      "36\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "load_data_path = 'all.tsv'\n",
    "data_path_test = 'test.tsv'\n",
    "labels = []\n",
    "texts = []\n",
    "len_x = 0\n",
    "sum_l = 0\n",
    "max_l = 0\n",
    "with open(load_data_path,'r',encoding = \"utf-8\") as f:\n",
    "    reader = csv.reader(f,delimiter = \"\\t\")\n",
    "    for row in reader:\n",
    "        text = row[0]\n",
    "        label = row[1]\n",
    "        if text == 'text':\n",
    "            continue\n",
    "\n",
    "        text.replace(\"\\n\",\"\")\n",
    "        texts.append(text)\n",
    "        labels.append(label)\n",
    "        l = len(text.split())\n",
    "        sum_l += l\n",
    "        if l > max_l:\n",
    "            max_l = l\n",
    "        if l > len_x:\n",
    "            len_x = l\n",
    "        \n",
    "print(sum_l / len(texts))\n",
    "print(len_x)\n",
    "print(max_l)\n",
    "print(len(np.unique(np.array(labels))))\n",
    "dicts = {}\n",
    "\n",
    "def gen_data(text):\n",
    "    return text.lower().split()\n",
    "for t in texts:\n",
    "    s = gen_data(t)\n",
    "    for w in s:\n",
    "        dicts[w] = dicts.get(w,0) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
