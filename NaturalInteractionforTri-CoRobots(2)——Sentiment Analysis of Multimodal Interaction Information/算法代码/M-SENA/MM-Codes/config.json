{
    "MODELS": {
        "LF_DNN": {
            "args": {
                "MOSI": {
                    "data_aligned": false,
                    "model_aligned": false,
                    "normalized": true,
                    "early_stop": 12,
                    "weight_decay": 0,
                    "hidden_dim_t": 128,
                    "hidden_dim_a": 64,
                    "hidden_dim_v": 128,
                    "text_out": 32,
                    "post_fusion_dim": 32,
                    "dropouts_a": 0,
                    "dropouts_v": 0,
                    "dropouts_t": 0,
                    "dropouts_f": 0,
                    "batch_size": 32,
                    "learning_rate": 0.001,
                    "grad_clip": 0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "MOSEI": {
                    "need_model_aligned": false,
                    "need_data_aligned": false,
                    "need_normalized": true,
                    "early_stop": 12,
                    "weight_decay": 0.0,
                    "hidden_dim_t": 64,
                    "hidden_dim_a": 128,
                    "hidden_dim_v": 128,
                    "text_out": 32,
                    "post_fusion_dim": 32,
                    "dropouts_a": 0.2,
                    "dropouts_v": 0.4,
                    "dropouts_t": 0.2,
                    "dropouts_f": 0.4,
                    "batch_size": 32,
                    "learning_rate": 0.001,
                    "grad_clip": 0.1,
                    "seed": 1234,
                    "num_workers": 8,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "SIMS": {
                    "need_model_aligned": false,
                    "need_data_aligned": false,
                    "need_normalized": true,
                    "early_stop": 12,
                    "weight_decay": 0,
                    "hidden_dim_t": 32,
                    "hidden_dim_a": 32,
                    "hidden_dim_v": 128,
                    "text_out": 32,
                    "post_fusion_dim": 32,
                    "dropouts_a": 0.2,
                    "dropouts_v": 0.1,
                    "dropouts_t": 0.1,
                    "dropouts_f": 0.2,
                    "batch_size": 32,
                    "learning_rate": 0.0005,
                    "grad_clip": 0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                }
            },
            "paper_name": "Benchmarking Multimodal Sentiment Analysis",
            "paper_url": "https://link.springer.com/chapter/10.1007/978-3-319-77116-8_13",
            "description": "Late Fusion Network."
        },
        "TFN": {
            "args": {
                "MOSI": {
                    "need_model_aligned": false,
                    "need_data_aligned": false,
                    "need_normalized": true,
                    "early_stop": 8,
                    "weight_decay": 0.0,
                    "hidden_dim_t": 256,
                    "hidden_dim_a": 32,
                    "hidden_dim_v": 256,
                    "text_out": 64,
                    "post_fusion_dim": 16,
                    "dropouts_a": 0.2,
                    "dropouts_v": 0.2,
                    "dropouts_t": 0.2,
                    "dropouts_f": 0.3,
                    "batch_size": 32,
                    "learning_rate": 0.0005,
                    "grad_clip": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "MOSEI": {
                    "need_model_aligned": false,
                    "need_data_aligned": false,
                    "need_normalized": true,
                    "early_stop": 8,
                    "weight_decay": 0.0,
                    "hidden_dim_t": 256,
                    "hidden_dim_a": 32,
                    "hidden_dim_v": 256,
                    "text_out": 64,
                    "post_fusion_dim": 16,
                    "dropouts_a": 0.2,
                    "dropouts_v": 0.2,
                    "dropouts_t": 0.2,
                    "dropouts_f": 0.3,
                    "batch_size": 32,
                    "learning_rate": 0.0005,
                    "grad_clip": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "SIMS": {
                    "need_model_aligned": false,
                    "need_data_aligned": false,
                    "need_normalized": true,
                    "early_stop": 12,
                    "weight_decay": 0.2,
                    "hidden_dim_t": 128,
                    "hidden_dim_a": 32,
                    "hidden_dim_v": 128,
                    "text_out": 64,
                    "post_fusion_dim": 16,
                    "dropouts_a": 0.1,
                    "dropouts_v": 0.2,
                    "dropouts_t": 0.3,
                    "dropouts_f": 0.1,
                    "batch_size": 32,
                    "learning_rate": 0.0005,
                    "grad_clip": 0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        1
                    ],
                    "KeyEval": "Loss"
                }
            },
            "paper_name": "Tensor Fusion Network for Multimodal Sentiment Analysis",
            "paper_url": "https://www.aclweb.org/anthology/D17-1115.pdf",
            "description": "Tensor Fusion Network."
        },
        "EF_LSTM": {
            "args": {
                "MOSI": {
                    "need_model_aligned": false,
                    "need_data_aligned": true,
                    "early_stop": 8,
                    "weight_decay": 0.0,
                    "hidden_dims": 64,
                    "num_layers": 2,
                    "dropout": 0.3,
                    "batch_size": 16,
                    "learning_rate": 0.001,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "MOSEI": {
                    "need_model_aligned": false,
                    "need_data_aligned": true,
                    "early_stop": 8,
                    "weight_decay": 0.0,
                    "hidden_dims": 64,
                    "num_layers": 2,
                    "dropout": 0.3,
                    "batch_size": 16,
                    "learning_rate": 0.001,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "SIMS": {
                    "need_model_aligned": false,
                    "need_data_aligned": true,
                    "early_stop": 8,
                    "weight_decay": 0.0,
                    "hidden_dims": 64,
                    "num_layers": 2,
                    "dropout": 0.3,
                    "batch_size": 16,
                    "learning_rate": 0.001,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                }
            },
            "paper_name": "Recognizing Emotions in Video Using Multimodal DNN Feature Fusion",
            "paper_url": "https://www.aclweb.org/anthology/W18-3302.pdf",
            "description": "Early Fusion Network Using LSTM."
        },
        "LMF": {
            "args": {
                "MOSI": {
                    "need_model_aligned": false,
                    "need_data_aligned": false,
                    "need_normalized": true,
                    "early_stop": 8,
                    "hidden_dim_t": 64,
                    "hidden_dim_a": 16,
                    "hidden_dim_v": 64,
                    "dropouts_a": 0.3,
                    "dropouts_v": 0.3,
                    "dropouts_t": 0.3,
                    "dropouts_f": 0.5,
                    "rank": 5,
                    "batch_size": 64,
                    "learning_rate": 0.002,
                    "factor_lr": 0.0001,
                    "weight_decay": 0.0001,
                    "grad_clip": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "SIMS": {
                    "need_model_aligned": false,
                    "need_data_aligned": false,
                    "need_normalized": true,
                    "early_stop": 8,
                    "hidden_dim_t": 64,
                    "hidden_dim_a": 16,
                    "hidden_dim_v": 64,
                    "dropouts_a": 0.3,
                    "dropouts_v": 0.3,
                    "dropouts_t": 0.3,
                    "dropouts_f": 0.5,
                    "rank": 5,
                    "batch_size": 64,
                    "learning_rate": 0.002,
                    "factor_lr": 0.0001,
                    "weight_decay": 0.0001,
                    "grad_clip": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "MOSEI": {
                    "need_model_aligned": false,
                    "need_data_aligned": false,
                    "need_normalized": true,
                    "early_stop": 8,
                    "hidden_dim_t": 64,
                    "hidden_dim_a": 16,
                    "hidden_dim_v": 64,
                    "dropouts_a": 0.3,
                    "dropouts_v": 0.3,
                    "dropouts_t": 0.3,
                    "dropouts_f": 0.5,
                    "rank": 5,
                    "batch_size": 64,
                    "learning_rate": 0.002,
                    "factor_lr": 0.0001,
                    "weight_decay": 0.0001,
                    "grad_clip": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                }
            },
            "paper_name": "Efficient Low-rank Multimodal Fusion with Modality-Specific Factors",
            "paper_url": "https://www.aclweb.org/anthology/P18-1209.pdf",
            "description": "Low-rank Memory Fusion Network."
        },
        "MFN": {
            "args": {
                "MOSI": {
                    "need_model_aligned": false,
                    "need_data_aligned": true,
                    "use_bert": false,
                    "early_stop": 8,
                    "weight_decay": 0.0,
                    "hidden_dims_l": 128,
                    "hidden_dims_a": 4,
                    "hidden_dims_v": 16,
                    "memsize": 64,
                    "windowsize": 2,
                    "NN1Config_drop": 0.7,
                    "NN1Config_shapes": 256,
                    "NN2Config_drop": 0.7,
                    "NN2Config_shapes": 128,
                    "gamma1Config_drop": 0.7,
                    "gamma1Config_shapes": 128,
                    "gamma2Config_drop": 0.2,
                    "gamma2Config_shapes": 32,
                    "outConfig_drop": 0.5,
                    "outConfig_shapes": 128,
                    "batch_size": 16,
                    "learning_rate": 0.001,
                    "grad_clip": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "MOSEI": {
                    "need_model_aligned": false,
                    "need_data_aligned": true,
                    "use_bert": false,
                    "early_stop": 8,
                    "weight_decay": 0.0,
                    "hidden_dims_l": 128,
                    "hidden_dims_a": 4,
                    "hidden_dims_v": 16,
                    "memsize": 64,
                    "windowsize": 2,
                    "NN1Config_drop": 0.7,
                    "NN1Config_shapes": 256,
                    "NN2Config_drop": 0.7,
                    "NN2Config_shapes": 128,
                    "gamma1Config_drop": 0.7,
                    "gamma1Config_shapes": 128,
                    "gamma2Config_drop": 0.2,
                    "gamma2Config_shapes": 32,
                    "outConfig_drop": 0.5,
                    "outConfig_shapes": 128,
                    "batch_size": 16,
                    "learning_rate": 0.001,
                    "grad_clip": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "SIMS": {
                    "need_model_aligned": true,
                    "need_data_aligned": false,
                    "use_bert": false,
                    "early_stop": 8,
                    "weight_decay": 0.0,
                    "hidden_dims_l": 128,
                    "hidden_dims_a": 4,
                    "hidden_dims_v": 16,
                    "memsize": 64,
                    "windowsize": 2,
                    "NN1Config_drop": 0.7,
                    "NN1Config_shapes": 256,
                    "NN2Config_drop": 0.7,
                    "NN2Config_shapes": 128,
                    "gamma1Config_drop": 0.7,
                    "gamma1Config_shapes": 128,
                    "gamma2Config_drop": 0.2,
                    "gamma2Config_shapes": 32,
                    "outConfig_drop": 0.5,
                    "outConfig_shapes": 128,
                    "batch_size": 16,
                    "learning_rate": 0.001,
                    "grad_clip": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                }
            },
            "paper_name": "Memory Fusion Network for Multi-View Sequential Learning",
            "paper_url": "https://arxiv.org/abs/1802.00927",
            "description": "Memory Fusion Network."
        },
        "Graph_MFN": {
            "args": {
                "MOSI": {
                    "need_model_aligned": false,
                    "need_data_aligned": true,
                    "use_bert": false,
                    "early_stop": 8,
                    "weight_decay": 0.0,
                    "hidden_dims_l": 128,
                    "hidden_dims_a": 16,
                    "hidden_dims_v": 128,
                    "memsize": 300,
                    "inner_node_dim": 64,
                    "NNConfig_drop": 0.2,
                    "NNConfig_shapes": 128,
                    "gamma1Config_drop": 0.0,
                    "gamma1Config_shapes": 128,
                    "gamma2Config_drop": 0.5,
                    "gamma2Config_shapes": 128,
                    "outConfig_drop": 0.0,
                    "outConfig_shapes": 32,
                    "batch_size": 64,
                    "learning_rate": 0.005,
                    "grad_clip": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "MOSEI": {
                    "need_model_aligned": false,
                    "need_data_aligned": true,
                    "use_bert": false,
                    "early_stop": 8,
                    "weight_decay": 0.0,
                    "hidden_dims_l": 128,
                    "hidden_dims_a": 16,
                    "hidden_dims_v": 128,
                    "memsize": 300,
                    "inner_node_dim": 64,
                    "NNConfig_drop": 0.2,
                    "NNConfig_shapes": 128,
                    "gamma1Config_drop": 0.0,
                    "gamma1Config_shapes": 128,
                    "gamma2Config_drop": 0.5,
                    "gamma2Config_shapes": 128,
                    "outConfig_drop": 0.0,
                    "outConfig_shapes": 32,
                    "batch_size": 64,
                    "learning_rate": 0.005,
                    "grad_clip": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "SIMS": {
                    "need_model_aligned": true,
                    "need_data_aligned": false,
                    "use_bert": false,
                    "early_stop": 8,
                    "weight_decay": 0.0,
                    "hidden_dims_l": 128,
                    "hidden_dims_a": 16,
                    "hidden_dims_v": 128,
                    "memsize": 300,
                    "inner_node_dim": 64,
                    "NNConfig_drop": 0.2,
                    "NNConfig_shapes": 128,
                    "gamma1Config_drop": 0.0,
                    "gamma1Config_shapes": 128,
                    "gamma2Config_drop": 0.5,
                    "gamma2Config_shapes": 128,
                    "outConfig_drop": 0.0,
                    "outConfig_shapes": 32,
                    "batch_size": 64,
                    "learning_rate": 0.005,
                    "grad_clip": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                }
            },
            "paper_name": "Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph",
            "paper_url": "https://www.aclweb.org/anthology/P18-1208.pdf",
            "description": "Dynamic Fusin Graph after Memory Fusion Network."
        },
        "MULT": {
            "args": {
                "MOSI": {
                    "need_data_aligned": false,
                    "need_model_aligned": false,
                    "early_stop": 8,
                    "use_bert": false,
                    "use_bert_finetune": false,
                    "attn_mask": true,
                    "update_epochs": 8,
                    "attn_dropout_a": 0.2,
                    "attn_dropout_v": 0.2,
                    "relu_dropout": 0.1,
                    "embed_dropout": 0.2,
                    "res_dropout": 0.1,
                    "dst_feature_dim_nheads_1": 40,
                    "dst_feature_dim_nheads_2": 10,
                    "batch_size": 8,
                    "learning_rate": 0.001,
                    "nlevels": 4,
                    "conv1d_kernel_size_l": 1,
                    "conv1d_kernel_size_a": 3,
                    "conv1d_kernel_size_v": 3,
                    "text_dropout": 0.2,
                    "attn_dropout": 0.2,
                    "output_dropout": 0.1,
                    "grad_clip": 0.8,
                    "patience": 20,
                    "weight_decay": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "MOSEI": {
                    "need_data_aligned": false,
                    "need_model_aligned": false,
                    "early_stop": 8,
                    "use_bert": false,
                    "use_bert_finetune": false,
                    "attn_mask": true,
                    "update_epochs": 8,
                    "attn_dropout_a": 0.2,
                    "attn_dropout_v": 0.2,
                    "relu_dropout": 0.1,
                    "embed_dropout": 0.2,
                    "res_dropout": 0.1,
                    "dst_feature_dim_nheads_1": 40,
                    "dst_feature_dim_nheads_2": 10,
                    "batch_size": 8,
                    "learning_rate": 0.001,
                    "nlevels": 4,
                    "conv1d_kernel_size_l": 1,
                    "conv1d_kernel_size_a": 3,
                    "conv1d_kernel_size_v": 3,
                    "text_dropout": 0.2,
                    "attn_dropout": 0.2,
                    "output_dropout": 0.1,
                    "grad_clip": 0.8,
                    "patience": 20,
                    "weight_decay": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "SIMS": {
                    "need_data_aligned": false,
                    "need_model_aligned": false,
                    "early_stop": 8,
                    "use_bert": false,
                    "use_bert_finetune": false,
                    "attn_mask": true,
                    "update_epochs": 8,
                    "attn_dropout_a": 0.2,
                    "attn_dropout_v": 0.2,
                    "relu_dropout": 0.1,
                    "embed_dropout": 0.2,
                    "res_dropout": 0.1,
                    "dst_feature_dim_nheads_1": 40,
                    "dst_feature_dim_nheads_2": 10,
                    "batch_size": 8,
                    "learning_rate": 0.001,
                    "nlevels": 4,
                    "conv1d_kernel_size_l": 1,
                    "conv1d_kernel_size_a": 3,
                    "conv1d_kernel_size_v": 3,
                    "text_dropout": 0.2,
                    "attn_dropout": 0.2,
                    "output_dropout": 0.1,
                    "grad_clip": 0.8,
                    "patience": 20,
                    "weight_decay": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                }
            },
            "paper_name": "Multimodal Transformer for Unaligned Multimodal Language Sequences",
            "paper_url": "https://github.com/yaohungt/Multimodal-Transformer",
            "description": "Multimodal Transformer for Unaligned Multimodal Language Sequences"
        },
        "MISA": {
            "args": {
                "MOSI": {
                    "need_data_aligned": false,
                    "need_model_aligned": false,
                    "early_stop": 8,
                    "use_bert": true,
                    "use_finetune": true,
                    "rnncell": "lstm",
                    "use_cmd_sim": true,
                    "update_epochs": 8,
                    "batch_size": 64,
                    "learning_rate": 0.0001,
                    "hidden_size": 128,
                    "dropout": 0.5,
                    "reverse_grad_weight": 1.0,
                    "diff_weight": 0.3,
                    "sim_weight": 1.0,
                    "sp_weight": 0.0,
                    "recon_weight": 1.0,
                    "grad_clip": 1.0,
                    "weight_decay": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "MOSEI": {
                    "need_data_aligned": false,
                    "need_model_aligned": false,
                    "early_stop": 8,
                    "use_bert": true,
                    "use_finetune": true,
                    "rnncell": "lstm",
                    "use_cmd_sim": true,
                    "update_epochs": 8,
                    "batch_size": 64,
                    "learning_rate": 0.0001,
                    "hidden_size": 128,
                    "dropout": 0.5,
                    "reverse_grad_weight": 1.0,
                    "diff_weight": 0.3,
                    "sim_weight": 1.0,
                    "sp_weight": 0.0,
                    "recon_weight": 1.0,
                    "grad_clip": 1.0,
                    "weight_decay": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                },
                "SIMS": {
                    "need_data_aligned": false,
                    "need_model_aligned": false,
                    "early_stop": 8,
                    "use_bert": true,
                    "use_finetune": true,
                    "rnncell": "lstm",
                    "use_cmd_sim": true,
                    "update_epochs": 8,
                    "batch_size": 64,
                    "learning_rate": 0.0001,
                    "hidden_size": 128,
                    "dropout": 0.5,
                    "reverse_grad_weight": 1.0,
                    "diff_weight": 0.3,
                    "sim_weight": 1.0,
                    "sp_weight": 0.0,
                    "recon_weight": 1.0,
                    "grad_clip": 1.0,
                    "weight_decay": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                }
            },
            "paper_name": "MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis",
            "paper_url": "https://github.com/declare-lab/MISA",
            "description": "Modality-Invariant and -Specific Representations"
        },
        "MTFN": {
            "args": {
                "SIMS": {
                    "tasks": "MTAV",
                    "need_model_aligned": false,
                    "need_data_aligned": false,
                    "need_normalized": true,
                    "early_stop": 8,
                    "hidden_dims_t": 256,
                    "hidden_dims_a": 32,
                    "hidden_dims_v": 256,
                    "text_out": 128,
                    "post_fusion_dim": 64,
                    "post_text_dim": 16,
                    "post_audio_dim": 4,
                    "post_video_dim": 8,
                    "dropouts_t": 0.3,
                    "dropouts_a": 0.3,
                    "dropouts_v": 0.3,
                    "post_dropouts_t": 0.4,
                    "post_dropouts_a": 0.4,
                    "post_dropouts_v": 0.4,
                    "post_dropouts_f": 0.4,
                    "batch_size": 64,
                    "learning_rate": 0.001,
                    "grad_clip": 0.0,
                    "M": 0.2,
                    "T": 0.4,
                    "A": 1.0,
                    "V": 0.6,
                    "text_weight_decay": 1e-05,
                    "audio_weight_decay": 0.001,
                    "video_weight_decay": 0.0001,
                    "weight_decay": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                }
            },
            "paper_name": "CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotations of Modality",
            "paper_url": "https://www.aclweb.org/anthology/2020.acl-main.343.pdf",
            "description": "Multi-task Multimodal Learning Framework for TFN."
        },
        "MLF_DNN": {
            "args": {
                "SIMS": {
                    "tasks": "MTAV",
                    "need_model_aligned": false,
                    "need_data_aligned": false,
                    "need_normalized": true,
                    "early_stop": 8,
                    "hidden_dims_t": 128,
                    "hidden_dims_a": 16,
                    "hidden_dims_v": 128,
                    "text_out": 32,
                    "post_fusion_dim": 128,
                    "post_text_dim": 32,
                    "post_audio_dim": 5,
                    "post_video_dim": 16,
                    "dropouts_t": 0.2,
                    "dropouts_a": 0.2,
                    "dropouts_v": 0.2,
                    "post_dropouts_t": 0.5,
                    "post_dropouts_a": 0.5,
                    "post_dropouts_v": 0.5,
                    "post_dropouts_f": 0.5,
                    "batch_size": 64,
                    "learning_rate": 0.0005,
                    "M": 0.8,
                    "T": 0.6,
                    "A": 0.4,
                    "V": 0.2,
                    "text_weight_decay": 0.0,
                    "audio_weight_decay": 0.0,
                    "video_weight_decay": 0.0,
                    "weight_decay": 0.0,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                }
            },
            "paper_name": "CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotations of Modality",
            "paper_url": "https://www.aclweb.org/anthology/2020.acl-main.343.pdf",
            "description": "Multi-task Multimodal Learning Framework for LF_DNN."
        },
        "MLMF": {
            "args": {
                "SIMS": {
                    "tasks": "MTAV",
                    "need_model_aligned": false,
                    "need_data_aligned": false,
                    "need_normalized": true,
                    "early_stop": 8,
                    "rank": 5,
                    "hidden_dims_t": 128,
                    "hidden_dims_a": 16,
                    "hidden_dims_v": 128,
                    "post_text_dim": 32,
                    "post_audio_dim": 5,
                    "post_video_dim": 16,
                    "dropouts_t": 0.2,
                    "dropouts_a": 0.2,
                    "dropouts_v": 0.2,
                    "post_dropouts_t": 0.5,
                    "post_dropouts_a": 0.5,
                    "post_dropouts_v": 0.5,
                    "post_dropouts_f": 0.5,
                    "batch_size": 64,
                    "learning_rate": 0.0005,
                    "M": 0.8,
                    "T": 0.6,
                    "A": 0.4,
                    "V": 0.2,
                    "text_weight_decay": 0.0001,
                    "audio_weight_decay": 1e-05,
                    "video_weight_decay": 0.0001,
                    "weight_decay": 0.001,
                    "seed": 1234,
                    "num_workers": 0,
                    "gpu_ids": [
                        0
                    ],
                    "KeyEval": "Loss"
                }
            },
            "paper_name": "CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotations of Modality",
            "paper_url": "https://www.aclweb.org/anthology/2020.acl-main.343.pdf",
            "description": "Multi-task Multimodal Learning Framework for LMF."
        }
    },
    "DATASETS": {
        "SIMS": {
            "unaligned": {
                "feature_path": "SIMS/Processed/features/unaligned_39.pkl",
                "seq_lens": [
                    39,
                    400,
                    55
                ],
                "feature_dims": [
                    768,
                    33,
                    709
                ],
                "num_classes": 3,
                "language": "Chinese",
                "annotations": {
                    "Negative": 0,
                    "Neutral": 1,
                    "Positive": 2
                }
            }
        },
        "MOSI": {
            "unaligned": {
                "feature_path": "MOSI/Processed/our_unaligned.pkl",
                "seq_lens": [
                    44,
                    620,
                    144
                ],
                "feature_dims": [
                    768,
                    33,
                    709
                ],
                "num_classes": 3,
                "language": "English",
                "annotations": {
                    "Negative": 0,
                    "Neutral": 1,
                    "Positive": 2
                }
            },
            "aligned": {
                "feature_path": "MOSI/Processed/aligned_50.pkl",
                "seq_lens": [
                    50,
                    50,
                    50
                ],
                "feature_dims": [
                    768,
                    5,
                    20
                ],
                "num_classes": 3,
                "language": "English",
                "annotations": {
                    "Negative": 0,
                    "Neutral": 1,
                    "Positive": 2
                }
            }
        },
        "MOSEI": {
            "unaligned": {
                "feature_path": "MOSEI/Processed/unaligned_50.pkl",
                "seq_lens": [
                    50,
                    500,
                    500
                ],
                "feature_dims": [
                    768,
                    74,
                    35
                ],
                "num_classes": 3,
                "language": "English",
                "annotations": {
                    "Negative": 0,
                    "Neutral": 1,
                    "Positive": 2
                }
            },
            "aligned": {
                "feature_path": "MOSEI/Processed/aligned_50.pkl",
                "seq_lens": [
                    50,
                    50,
                    50
                ],
                "feature_dims": [
                    768,
                    74,
                    35
                ],
                "num_classes": 3,
                "language": "English",
                "annotations": {
                    "Negative": 0,
                    "Neutral": 1,
                    "Positive": 2
                }
            }
        }
    }
}